{% extends 'base.attached.class' %}

{% block content %}
{% if is_test or to_json %}
import java.util.Arrays;

{% endif %}
class {{ class_name }} {

    private enum Activation { IDENTITY, LOGISTIC, RELU, TANH, SOFTMAX }

    private Activation hidden;
    private Activation output;
    private double[][] network;
    private double[][][] weights;
    private double[][] bias;

    public {{ class_name }}(String hidden, String output, int[] layers, double[][][] weights, double[][] bias) {
        this.hidden = Activation.valueOf(hidden.toUpperCase());
        this.output = Activation.valueOf(output.toUpperCase());
        this.network = new double[layers.length + 1][];
        for (int i = 0, l = layers.length; i < l; i++) {
            this.network[i + 1] = new double[layers[i]];
        }
        this.weights = weights;
        this.bias = bias;
    }

    public {{ class_name }}(String hidden, String output, int neurons, double[][][] weights, double[][] bias) {
        this(hidden, output, new int[] { neurons }, weights, bias);
    }

    private int findMax(double[] nums) {
        int i, l = nums.length, idx = 0;
        for (i = 0; i < l; i++) {
            idx = nums[i] > nums[idx] ? i : idx;
        }
        return idx;
    }

    private double[] compute(Activation activation, double[] v) {
        int i, l = v.length;
        switch (activation) {
            case LOGISTIC:
                for (i = 0; i < l; i++) {
                    v[i] = 1. / (1. + Math.exp(-v[i]));
                }
                break;
            case RELU:
                for (i = 0; i < l; i++) {
                    v[i] = Math.max(0, v[i]);
                }
                break;
            case TANH:
                for (i = 0; i < l; i++) {
                    v[i] = Math.tanh(v[i]);
                }
                break;
            case SOFTMAX:
                double max = Double.NEGATIVE_INFINITY;
                for (double x : v) {
                    if (x > max) {
                        max = x;
                    }
                }
                for (i = 0; i < l; i++) {
                    v[i] = Math.exp(v[i] - max);
                }
                double sum = 0.;
                for (double x : v) {
                    sum += x;
                }
                for (i = 0; i < l; i++) {
                    v[i] /= sum;
                }
                break;
        }
        return v;
    }

    private void resetNetwork() {
        for (int i = 1, l = this.network.length - 1; i < l; i++) {
            for (int j = 0; j < this.network[i].length; j++) {
                this.network[i][j] = 0;
            }
        }
    }

    private double[] feedForward(double[] neurons) {
        this.network[0] = neurons;
        for (int i = 0; i < this.network.length - 1; i++) {
            for (int j = 0; j < this.network[i + 1].length; j++) {
                this.network[i + 1][j] = this.bias[i][j];
                for (int l = 0; l < this.network[i].length; l++) {
                    this.network[i + 1][j] += this.network[i][l] * this.weights[i][l][j];
                }
            }
            if ((i + 1) < (this.network.length - 1)) {
                this.network[i + 1] = this.compute(this.hidden, this.network[i + 1]);
            }
        }
        this.network[this.network.length - 1] = this.compute(this.output, this.network[this.network.length - 1]);
        this.resetNetwork();
        return this.network[this.network.length - 1];
    }

    public int predict(double[] neurons) {
        double[] lastLayer = this.feedForward(neurons);
        if (lastLayer.length == 1) {
            if (lastLayer[0] > .5) {
                return 1;
            }
            return 0;
        }
        return findMax(lastLayer);
    }

    public double[] predictProba(double[] neurons) {
        double[] lastLayer = this.feedForward(neurons);
        if (lastLayer.length == 1) {
            return new double[] {lastLayer[0], 1 - lastLayer[0]};
        }
        return lastLayer;
    }

    public static void main(String[] args) {
        int nFeatures = {{ n_features }};
        if (args.length != nFeatures) {
            throw new IllegalArgumentException("You have to pass " +  String.valueOf(nFeatures) + " features.");
        }

        // Features:
        double[] features = new double[args.length];
        for (int i = 0, l = args.length; i < l; i++) {
            features[i] = Double.parseDouble(args[i]);
        }

        // Model data:
        {{ layers }}
        {{ weights }}
        {{ bias }}

        // Estimator:
        {{ class_name }} clf = new {{ class_name }}("{{ hidden_activation }}", "{{ output_activation }}", layers, weights, bias);

        {% if is_test or to_json %}
        // Get JSON:
        int prediction = clf.predict(features);
        double[] probabilities = clf.predictProba(features);
        System.out.println("{\"predict\": " + String.valueOf(prediction) + ", \"predict_proba\": " + String.join(",", Arrays.toString(probabilities)) + "}");
        {% else %}
        // Get class prediction:
        int prediction = clf.predict(features);
        System.out.println("Predicted class: #" + String.valueOf(prediction));

        // Get class probabilities:
        double[] probabilities = clf.predictProba(features);
        for (int i = 0; i < probabilities.length; i++) {
            System.out.println("Probability of class #" + i + " : " + String.valueOf(probabilities[i]));
        }
        {% endif %}

    }
}
{% endblock %}